---
title: "Language Without Borders: A Step-by-Step Guide to Analyzing1Webcam Eye-Tracking Data for L2 Research"
date: 2025-02-17
author:
  - name: Jason Geller
    affiliation: Boston College
  - name: Yanina Prystauka
    affiliation: University of Bergen
  - name: Sarah E. Colby
    affiliation: University of Ottawa
  - name: Julia R. Drouin 
    affiliation: University of North Carolina at Chapel Hill
    
categories: 
  - L2 processing
  - Webcame eye-tracking
  - R
  - Spoken word recognition
  - VWP 
pub-info:
  reference: "<strong>Geller, J.</strong>, Prystauka, Y., Colby, S. E., & Drouin, J. R. (2025). Language Without Borders: A Step-by-Step Guide to Analyzing Webcam Eye-Tracking Data for L2 Research. https://doi.org/10.31234/osf.io/7jqea_v5"
  links:
    - name: Preprint
      url: https://osf.io/preprints/psyarxiv/7jqea_v5
      icon: ai ai-psyarxiv-square
    - name: OSF
      url: https://osf.io/be4jd/
      icon:  ai ai-osf-square
    - name: Github
      url: https://github.com/jgeller112/L2_VWP_Webcam
      icon: fa-brands fa-github-square
doi: https://doi.org/10.31234/osf.io/7jqea_v5
---

# Abstract

Eye-tracking has become a valuable tool for studying cognitive processes in second language (L2) acquisition and bilingualism (Godfroid et al., 2024). While research-grade infrared eye-trackers are commonly used, there are a number of issues that limit its wide-spread adoption. Recently, consumer-based webcam eye-tracking has emerged as an attractive alternative, requiring only internet access and a personal webcam. However, webcam eye-tracking presents unique design and preprocessing challenges that must be addressed for valid results. To help researchers overcome these challenges, we developed a comprehensive tutorial focused on visual world webcam eye-tracking for L2 language research. Our guide will cover all key steps,from design to data preprocessing and analysis, where we highlight the R package webgazeR, which is open source and freely available for download and installation:https://github.com/jgeller112/webgazeR. We offer best practices for environmental conditions, participant instructions, and tips for designing visual world experiments with webcam eye-tracking. To demonstrate these steps, we analyze data collected through the Gorilla platform (Anwyl-Irvine et al., 2020) using a single word Span-ish visual world paradigm (VWP) and show competition within and between L2/L1.This tutorial aims to empower researchers by providing a step-by-step guide to successfully conduct visual world webcam-based eye-tracking studies. To follow along with this tutorial, please download the entire manuscript and its accompanying code with data from here: https://github.com/jgeller112/L2_VWP_Webcam
