---
title: 'Analzying GazePoint Pupil Data With GazeR'
layout: single-sidebar
date: '2021-04-21'
slug: gp-pup
categories:
  - R
tags:
  - R
  - eye-tracking
  - pupil

subtitle: 'Using gazeR to analyze GazePoint Pupil Data'
summary: 'I demonstrate how to analyze pupil data from a GazePoint tracker with my eye-tracking R package gazeR.'
authors: ['Jason Geller']
lastmod: ''
featured: yes
image:
  caption:
  placement: 2
  focal_point: 'Center'
  preview_only: no
projects: []
links:
- icon: map-marked-alt
  icon_pack: fas
  name: Interactive Map
  url: /blog/2021-04-21-gazePoint_gazer_2/gazepoint.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message=FALSE, 
                      error=TRUE)
```

In this vignette I am going to show you how to read in a GazePoint data file along with some behavioral data and use `gazeR` to preprocess the data.  

Special thanks to Matthew K Robinson (Twitter:@matthewkrobinson) for letting me use some data from an auditory oddball task he conducted on himself (we do what we have to do as researchers :D): see Tweet below. 

<blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr">i&#39;m just a guy, running himself through auditory oddball tasks on his new eye-tracker, asking it to love him back. <a href="https://t.co/wPb97MZuNF">pic.twitter.com/wPb97MZuNF</a></p>&mdash; Matthew K. Robison (@matthewkrobison) <a href="https://twitter.com/matthewkrobison/status/1384208857790959617?ref_src=twsrc%5Etfw">April 19, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

To get started, we need to load in some important packages and read in the GP data files. 

# Load Packages

```{r}
library(tidyverse)
library(remotes)
remotes::install_github("dmirman/gazer")
library(gazer)
library(data.table)
library(here)
remotes::install_github("tmalsburg/saccades/saccades", dependencies=TRUE)
library(saccades)
```

# Read Data

```{r}


pd <- fread('oddball_eye_13.tsv') # eye data 
bs<-fread('oddball_13.tsv') # behave data

head(pd)

head(bs)

```

What we are going to do is run the GazePoint file through the `merge_gazepoint` function. The function below takes a list of files called file_list and merges all the files together, appends a subject column, creates a trial column using the USER column (GazePoint only allows  messages through this channel), creates a time variable (in milliseconds). In the `merge_gazepoint` function the `trail_msg` argument requires users to denote a message used in the USER column that references the start of the trial--in our case the `START` message denotes the start of a new trial. This is a solution by Matt Robinson, but there are other ways one could extract the trial number. What I have done in the past is append a message with the trial iteration (e.g., START_1) in Python and use the `separate` function to get the trial number. 

```{r}

# A "monocular mean" averages both eyes together. If data is available in just
# one eye, use the available value as the mean, unless we need_both is TRUE.
#' @param x1 pupil left
#' @param x2 pupil right
#' @return vector with monocular mean values
compute_monocular_mean <- function(x1, x2) {
  xm <- rowMeans(cbind(x1, x2), na.rm = TRUE)
  # NaN => NA
  ifelse(is.nan(xm), NA, xm)
}


# function for processing GazePoint data
merge_gazepoint <- function (file_list, trial_msg = "START"){
  #file list is path to .xls files
  #vroom is faster
  library(data.table)
  
  file_ids=str_replace_all(basename(file_list),"([:alpha:]|[:punct:])","") # remove everything but numeric values
                   
  data <- map2(file_list, file_ids, ~fread(.x) %>% 
    mutate(id = .y))  %>% 
    bind_rows()

  
  d = data %>%
    dplyr::rowwise() %>%
    dplyr::mutate(pupil=compute_monocular_mean(RPMM, LPMM)) %>% # average both eyes
             dplyr::ungroup() %>%
           dplyr::mutate(pupil = ifelse(RPMMV == 0|LPMMV == 0, 0, pupil),  #missing data labeled as blinks
         new_trial = ifelse(USER == trial_msg & lag(USER) != trial_msg, 1, 0), # Label new trials
         trial = cumsum(new_trial), # Create a trial variable
         time = floor(TIME*1000)) %>%
    group_by(trial) %>%
    dplyr::mutate(time=time - min(time)) %>%
    ungroup() %>%
  dplyr::select(id, time,trial,pupil,BPOGX, BPOGY, USER) %>%
    dplyr::rename("message" = "USER", "subject"= "id", "x" = "BPOGX", "y" = "BPOGY") %>% 
    dplyr::filter(trial > 0)
  
  return(d)
}

```

# Merge Files 
```{R}

setwd(here()) # setwd

gp_file<-list.files(here::here(), pattern = "eye_13.tsv") # get files 

setwd(here())
      
d=merge_gazepoint(gp_file, trial_msg = "START")

d$subject<-as.numeric(d$subject)

pdb <- full_join(bs, d)

pdb <- as_tibble(pdb)

pdb

```

# Blinks

## Finding Blinks

The GazePoint data does not indicate where blinks occurred. What we are going to do is use the `blink_detect` function in gazer. This relies on the `saccades` package (https://github.com/tmalsburg/saccades) which uses a velocity based measure based on X,Y coordinates to find blinks. Once we find the blinks we can change the pupil size at that time point as NA and interpolate over it.  

As a note, the GazePoint does not seem to sample consistently. In this case, it samples every 16 or 17 ms. This is a problem for some other blink detection measures (e.g., the noise based pupil function). One soultion would be to downsample the data at the onset so there is consistancy from sample to sample. 

```{r}

blinks_merge<- blink_detect(pdb)

 blinks <- blinks_merge %>%
        dplyr::group_by(grp = cumsum(!is.na(startend))) %>%
        dplyr::mutate(Label = replace(startend, first(startend) == 'start', 'start')) %>% #extends the start message forward until end message
        dplyr::ungroup() %>%
        # label blinks as 1
        dplyr::select(subject, trial, time, x, y, pupil, message, tone,  Label, -grp)
 
 
 blinks_data <- blinks  %>%
        dplyr::mutate(blink=ifelse(!is.na(Label), 1, 0), pupil=ifelse(blink==1 | pupil==0, NA, pupil))%>%
        dplyr::ungroup()%>%
        dplyr::select(subject, time, trial, pupil, x, y, trial, message, tone, blink, -Label)
 

```

Here is a look at the trials containing blinks: 

```{r}

blinks_data %>% 
  filter(blink==1) %>%
  head()%>%
  knitr::kable()

```
##  Extending Blinks

I am extending blinks 100 ms forward and backward in time. 

```{r pressure, echo=FALSE}

  #Extend Blinks
pup_extend<- blinks_data %>%
  mutate(pupil=na_if(pupil, 0)) %>%
  group_by(subject, trial) %>%
  mutate(extendpupil=extend_blinks(pupil, fillback=100, fillforward=100, hz=60)) %>%
  ungroup() 
```

## Interpolate Blinks

Here let's linearly interpolate the blinks and then smooth the data using a 5-point moving average. 

```{r}
# Smooth and Interpolate
smooth_interp <- smooth_interpolate_pupil(pup_extend, pupil="pupil", extendpupil="extendpupil", extendblinks=TRUE, step.first="smooth", maxgap=Inf, type="linear", hz=60, n=5)
```

# Plot Interpolated Trial 

```{r}

interp_graph <- smooth_interp  %>%
  dplyr::filter(trial=="400")

bold <- element_text(face = "bold", color = "black", size = 14) #axis bold
#Graph interpolation
pup_g<- ggplot(interp_graph, aes(x= time, y= pupil)) + geom_point()+ geom_line(colour="black") +
  geom_line(aes(x=time, y=pup_interp), colour="darkgreen") + xlab("Time (ms)") + ylab("Pupil Size (mm)") + theme_bw() + theme(axis.title.y=element_text(size = 16, face="bold"), axis.title.x = element_text(size=16, face="bold"), axis.text.x=element_text(size = 12, face="bold"), axis.text.y=element_text(size=12, face="bold"))
print(pup_g)


```

# Baseline Correction

Here we will do a subtractive baseline correction taking 250 ms before the onset of the tone as baseline. 

```{r}

#use messages to baseline correct
baseline_pupil<-baseline_correction_pupil(smooth_interp, pupil_colname="pup_interp", baseline_window=c(0,250), baseline_method = "sub")

head(baseline_pupil)

```

# Missing Data

Let's see how much missing data there is and remove trials with greater than 20% missing data. 
```{r}


pup_missing<-count_missing_pupil(baseline_pupil, missingthresh = .5)
# remove outliers
```

I remove about 15 percent of trials. 

# Unlikely Pupil Sizes

Now let's keep pupil diameter sizes between 2 mm and 9 mm

```{r}
pup_outliers<-pup_missing %>%
  dplyr::filter (pup_interp  >= 2, pup_interp <= 9)
```

# MAD 

Get rid of artifacts we might have missed during some earlier steps. 

```{r}  
  #MAD removal
max_removal<-pup_missing  %>%
  dplyr::group_by(subject, trial) %>%
  dplyr::mutate(speed=speed_pupil(pup_interp,time)) %>%
  dplyr::mutate(MAD=calc_mad(speed)) %>%
  dplyr::filter(speed < MAD)

```

# Onset

Let's only look fron the start of the trial until 1500 ms  

```{r}
baseline_pupil_onset<-max_removal %>%
  dplyr::group_by(subject, trial) %>%
  dplyr::filter(time <= 1500) %>%
  select(subject, trial, time,baselinecorrectedp, tone, time,message,baselinecorrectedp)
```

# Downsample

Downsample the time-course to 50 ms. 

```{r}
#downsample
timebins1<- downsample_gaze(baseline_pupil_onset, bin.length=50, timevar = "time", aggvars = c("subject", "tone", "timebins"), type="pupil")

timebins1
```

# Visualize Time-course

```{r}

cursive_plot <-ggplot(timebins1)+
  aes(timebins, aggbaseline, linetype=tone, color=tone) +
  stat_summary(fun = "mean", geom = "line", size = 1) +
  theme_bw() +
  labs(x ="Time (ms)",y ="Pupil Dilation (baseline - pupil))") +
  geom_hline(yintercept=0.0)

print(cursive_plot)

```

This looks very similar to the one in the Tweet albeit a bit smoother as a result of the extra preprocessing done.

