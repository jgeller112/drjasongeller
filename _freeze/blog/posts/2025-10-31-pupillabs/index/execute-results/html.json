{
  "hash": "a4c6b3bac25a3f410a171620587b8364",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analzying Pupil Labs Neon Data With GazeR\"\ndate: 2025-10-31\ndescription: \"I demonstrate how to analyze pupil data from Pupil Labs Neon mobile eye-tracker with my eye-tracking R package gazeR.\"\ncategories:\n  - r\n  - pupillometry\n  - statistics\n\nformat:\n  html: \n    theme: dracula\n    css: halloween.css\n        \nexecute: \n  echo: true\n  message: false\n  warning: false\n---\n\nðŸŽƒ Happy Halloween, goils and boils! ðŸ‘»\n\nI have a spooktacular blog post for you todayâ€”one that dives into the mysterious world of pupil data from Pupil Labs Neon glasses. Weâ€™re currently using the Neon in the classroom to study mind wandering and attention. However, these mobile eye trackers arenâ€™t just for field studiesâ€”they shine in the lab too.\n\nTo demonstrate this, I created a simple PsychoPy experiment that interfaces seamlessly with the Neon (you can find it here: https://osf.io/txz59/overview ). In the task, participants view a bright sun for 30 seconds followed by a dark patch for another 30 seconds. The pupil responds to basic visual features like brightnessâ€”constricting in light and dilating in the dark.\n\n![](images/Eye_dilate.gif){fig-align=\"center\"}\n\nIn this post, Iâ€™ll show how the Neon glasses can capture these pupillary dynamics and how you can use my R package {gazeR} to preprocess pupil data collected from Pupil Labs devices.\n\n## gazeR Pupil labs Functions\n\nOnce you collect data with Pupil Labs Neon, your recordings live in Pupil Cloud. Export the Time Series for each recording (CSV export). After the export finishes, youâ€™ll have a folder per participant/recording containing multiple CSV files.\n\n![](images/timeseries.jpg){fig-align=\"center\"}\n\nFrom each participant folder, we use exactly three files:\n\ngaze.csv â€” gaze samples (timestamps, x/y pixels, fixations, blinks)\n\n3d_eye_states.csv â€” pupil diameters (left/right, in mm)\n\nevents.csv â€” experiment events/messages (e.g., trial markers)\n\n![](images/pl_files.jpg){fig-align=\"center\"}\n\nI created two new functions to read and process this data from Pupil Labs:\n\n`parse_pl()` and `process_all_subjects_PL()`. Both work in tandem to prepare Neon data for use with {gazeR}.\n\n## What the functions do\n\n`parse_pl(subject_dir, aoi = FALSE, start_mode = c(\"any\",\"exact\"), start_messages = NULL, max_event_lag_ms = 20)`\n\nProcesses one participant:\n\n1.  Reads the three CSVs and converts timestamps to milliseconds.\n\n2.  Joins pupil data to gaze samples.\n\n3.  Aligns each non-recording event (events.csv) to the nearest gaze row (within max_event_lag_ms).\n\n4.  If aoi=TRUE, it can read in the surface or AOI files. Here we used the marker mapper to map gaze on the screen of the laptop I used to record the data.\n\n5.  Creates trial indices:\n\n-   start_mode = \"any\" â†’ any non-empty message (excluding recording.begin/.end) starts a new trial.\n\n-   start_mode = \"exact\" â†’ only messages listed in start_messages start a new trial (robust to case/whitespace/hyphen differences).\n\n6.  Resets time to 0 at the first row of each trial.\n\n7.  Returns a tidy tibble ready for {gazeR}: `subject, trial, time, x, y, pupil, blink, message.`\n\n::: callout-note\nIf you read in surface data, it will include whether gaze was found on the surface or not as well as x,y surface coordinates.\n:::\n\n`process_all_subjects_PL(root_dir, output_dir = file.path(root_dir, \"processed\"), ...)`\n\nBatch-processes **all** immediate subfolders of `root_dir` using `parse_pl()`, writes one CSV per subject plus a combined files\n\n-   Per-subject files: `{output_dir}/{SUBJECT}_processed.cs`\n\n    Combined file: `{output_dir}/all_subjects_processed.csv`\n\nAny additional arguments (`...`) are passed straight to `parse_pl()` (e.g., `start_mode`, `start_messages`, `max_event_lag_ms`).\n\n# Example Dataset\n\nLet's read in the dataset created from the above functions.\n\nWe will load in {gazeR} and needed libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"dmirman/gazer\") # gazer package\nlibrary(gazer) # load in \nlibrary(tidyverse) # viz\nlibrary(knitr) # tables\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsub_pl = read.csv(\"https://osf.io/zf2qu/download\")\nkable(head(sub_pl))\n```\n\n::: {.cell-output-display}\n\n\n|subject                      | trial|      time|       x|       y|   pupil|blink |message             |\n|:----------------------------|-----:|---------:|-------:|-------:|-------:|:-----|:-------------------|\n|2025-10-31_12-48-26-74964918 |     1|  0.000000| 813.938| 606.636| 4.24975|FALSE |trial-started-light |\n|2025-10-31_12-48-26-74964918 |     1|  5.005127| 815.400| 608.674| 4.21485|FALSE |                    |\n|2025-10-31_12-48-26-74964918 |     1|  9.994873| 815.163| 607.715| 4.23690|FALSE |                    |\n|2025-10-31_12-48-26-74964918 |     1| 14.994629| 814.249| 606.579| 4.25715|FALSE |                    |\n|2025-10-31_12-48-26-74964918 |     1| 19.994629| 812.541| 607.620| 4.22035|FALSE |                    |\n|2025-10-31_12-48-26-74964918 |     1| 24.994873| 815.149| 607.083| 4.20380|FALSE |                    |\n\n\n:::\n:::\n\n\nLet's take a look at the data we have.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis is what the pupil data looks like for the entire time course.\n\n## Extending Blinks\n\nWe see dips in the pupil signalâ€”these are most likely caused by blinks. Pupil Labs includes a blink detection algorithm, which weâ€™ll use here. We first set pupil size values corresponding to blinks to NA, then use extend_blinks()to extend blinks 100 ms forward and backward in time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  #Extend Blinks\npup_extend<- sub_pl |>\n  mutate(pupil=ifelse(blink==TRUE, NA, pupil)) |>\n  group_by(subject, trial) |>\n  mutate(extendpupil=extend_blinks(pupil, fillback=100, fillforward=100, hz=200)) |>\n  ungroup() \n```\n:::\n\n\n## Interpolate blinks\n\nNext, we linearly interpolate over blinks and smooth the data using a 5-point moving average.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Smooth and Interpolate\nsmooth_interp <- smooth_interpolate_pupil(pup_extend, pupil=\"pupil\", extendpupil=\"extendpupil\", extendblinks=TRUE, step.first=\"smooth\", maxgap=Inf, type=\"linear\", hz=200, n=5)\n```\n:::\n\n\nThen, calculate missing data and remove trials with more than 50% missing data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n pup_missing<-count_missing_pupil(smooth_interp, missingthresh = .5)\n```\n:::\n\n\n## Unlikely Pupil Sizes\n\nNow, keep only plausible pupil diameters between 2 mm and 9 mm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npup_outliers<-pup_missing |>\n  dplyr::filter (pup_interp  >= 2, pup_interp <= 9)\n```\n:::\n\n\n## MAD\n\nGet rid of artifacts we might have missed during some earlier steps.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  #MAD removal\nmax_removal<-pup_missing  |>\n  dplyr::group_by(subject, trial) |>\n  dplyr::mutate(speed=speed_pupil(pup_interp,time)) |>\n  dplyr::mutate(MAD=calc_mad(speed)) |>\n  dplyr::filter(speed < MAD)\n```\n:::\n\n\n## Onset\n\nLet's only look from the start of the trial until 1000 ms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npupil_onset<-max_removal |>\n  dplyr::group_by(subject, trial) |>\n  dplyr::filter(time <= 1000) |>\n  select(subject, trial, time, pup_interp)\n```\n:::\n\n\n## Downsample\n\nDownsample the time-course to 100 ms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#downsample\ntimebins1<- downsample_gaze(pupil_onset, bin.length=100, pupil=\"pup_interp\", timevar = \"time\", aggvars = c(\"subject\", \"trial\", \"timebins\"), type=\"pupil\")\n\nkable(head(timebins1))\n```\n\n::: {.cell-output-display}\n\n\n|subject                      | trial| timebins| aggbaseline|\n|:----------------------------|-----:|--------:|-----------:|\n|2025-10-31_12-48-26-74964918 |     1|        0|    4.233871|\n|2025-10-31_12-48-26-74964918 |     1|      100|    4.251030|\n|2025-10-31_12-48-26-74964918 |     1|      200|    4.264931|\n|2025-10-31_12-48-26-74964918 |     1|      300|    4.296879|\n|2025-10-31_12-48-26-74964918 |     1|      400|    4.323454|\n|2025-10-31_12-48-26-74964918 |     1|      500|    4.247790|\n\n\n:::\n:::\n\n\n## Visualize Time-course\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Surface Looks\n\nWhat does the data look like if we constrain the analyses to only include looks to the laptop screen?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsub_pl = read.csv(\"https://osf.io/enf6u/download\")\nkable(head(sub_pl))\n```\n\n::: {.cell-output-display}\n\n\n|subject | trial|      time|gaze_detected_on_surface | gaze_position_on_surface_x_normalized| gaze_position_on_surface_y_normalized|   pupil|blink |message             | fixation_id|\n|:-------|-----:|---------:|:------------------------|-------------------------------------:|-------------------------------------:|-------:|:-----|:-------------------|-----------:|\n|test1   |     1|  0.000000|TRUE                     |                              0.503664|                              0.523080| 4.28100|FALSE |trial-started-light |           1|\n|test1   |     1|  5.000000|TRUE                     |                              0.505029|                              0.524774| 4.24610|FALSE |                    |           1|\n|test1   |     1|  9.999756|TRUE                     |                              0.505353|                              0.521651| 4.22220|FALSE |                    |           1|\n|test1   |     1| 15.011963|TRUE                     |                              0.505129|                              0.522213| 4.23325|FALSE |                    |           1|\n|test1   |     1| 20.000000|TRUE                     |                              0.503285|                              0.520440| 4.27000|FALSE |                    |           1|\n|test1   |     1| 25.000000|TRUE                     |                              0.504079|                              0.509780| 4.25900|FALSE |                    |           1|\n\n\n:::\n:::\n\n\nLet's take a look at the data we have.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nThis is what the pupil data looks like for the entire time course.\n\n## Extending Blinks\n\nWe see dips in the pupil signalâ€”these are most likely caused by blinks. Pupil Labs includes a blink detection algorithm, which weâ€™ll use here. We first set pupil size values corresponding to blinks to NA, then use extend_blinks()to extend blinks 100 ms forward and backward in time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  #Extend Blinks\npup_extend<- sub_pl |>\n  mutate(pupil=ifelse(blink==TRUE, NA, pupil)) |>\n  group_by(subject, trial) |>\n  mutate(extendpupil=extend_blinks(pupil, fillback=100, fillforward=100, hz=200)) |>\n  ungroup() \n```\n:::\n\n\n## Interpolate blinks\n\nNext, we linearly interpolate over blinks and smooth the data using a 5-point moving average.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Smooth and Interpolate\nsmooth_interp <- smooth_interpolate_pupil(pup_extend, pupil=\"pupil\", extendpupil=\"extendpupil\", extendblinks=TRUE, step.first=\"smooth\", maxgap=Inf, type=\"linear\", hz=200, n=5)\n```\n:::\n\n\nThen, calculate missing data and remove trials with more than 50% missing data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n pup_missing<-count_missing_pupil(smooth_interp, missingthresh = .5)\n```\n:::\n\n\n## Unlikely Pupil Sizes\n\nNow, keep only plausible pupil diameters between 2 mm and 9 mm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npup_outliers<-pup_missing |>\n  dplyr::filter (pup_interp  >= 2, pup_interp <= 9)\n```\n:::\n\n\n## MAD\n\nGet rid of artifacts we might have missed during some earlier steps.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  #MAD removal\nmax_removal<-pup_missing  |>\n  dplyr::group_by(subject, trial) |>\n  dplyr::mutate(speed=speed_pupil(pup_interp,time)) |>\n  dplyr::mutate(MAD=calc_mad(speed)) |>\n  dplyr::filter(speed < MAD)\n```\n:::\n\n\n## Onset\n\nLet's only look from the start of the trial until 1000 ms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npupil_onset<-max_removal |>\n  dplyr::group_by(subject, trial) |>\n  dplyr::filter(time <= 1000, gaze_detected_on_surface==TRUE) |>\n  select(subject, trial, time, pup_interp)\n```\n:::\n\n\n## Downsample\n\nDownsample the time-course to 100 ms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#downsample\ntimebins1<- downsample_gaze(pupil_onset, bin.length=100, pupil=\"pup_interp\", timevar = \"time\", aggvars = c(\"subject\", \"trial\", \"timebins\"), type=\"pupil\")\n\nkable(head(timebins1))\n```\n\n::: {.cell-output-display}\n\n\n|subject | trial| timebins| aggbaseline|\n|:-------|-----:|--------:|-----------:|\n|test1   |     1|        0|    4.246710|\n|test1   |     1|      100|    4.260450|\n|test1   |     1|      200|    4.274502|\n|test1   |     1|      300|    4.313692|\n|test1   |     1|      400|    4.301169|\n|test1   |     1|      500|    4.196293|\n\n\n:::\n:::\n\n\n## Visualize Time-course\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=672}\n:::\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}